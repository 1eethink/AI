{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a42e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1116d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True  Use << CUDA >>\n",
      "PyTorch Version: 1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('CUDA:', torch.cuda.is_available(), ' Use << {} >>'.format(device.upper()))\n",
    "print('PyTorch Version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25666cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "\n",
    "        dataframe = pd.read_csv(file_name)\n",
    "        \n",
    "        x = dataframe.iloc[:,0:45].values # inputs\n",
    "        y = dataframe.iloc[:, 45].values # labels\n",
    "        y = (y-100)/100 # labels must start at 0 so adjust this to your data\n",
    "        \n",
    "        #converting to torch tensors\n",
    "        self.x = torch.tensor(x, dtype=torch.float32) \n",
    "        self.y = torch.tensor(y, dtype=torch.int64)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0774eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSet(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eceab37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = CSVDataset('.csv') # adjust this to your file name\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data.x, input_data.y, test_size=0.2, shuffle = True)\n",
    "\n",
    "# Save train data set\n",
    "f = open('.csv','w', newline='')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    wr.writerow([X_train[i][0:45], y_train[i]])\n",
    "    \n",
    "f.close()\n",
    "\n",
    "# Save test data set\n",
    "f = open('.csv','w', newline='')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    wr.writerow([X_test[i][0:45], y_test[i]])\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a71a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([4325, 45]) torch.Size([4325])\n",
      "Testing Shape torch.Size([1082, 45]) torch.Size([1082])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6981c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4325, 5, 9])\n",
      "torch.Size([1082, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "X_train_final = torch.reshape(X_train, (X_train.shape[0], 5, int(X_train.shape[1]/5)))\n",
    "X_test_final = torch.reshape(X_test, (X_test.shape[0], 5, int(X_test.shape[1]/5)))\n",
    "\n",
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a0fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes # number of classes\n",
    "        self.num_layers = num_layers # number of layers\n",
    "        self.input_size = input_size # input size\n",
    "        self.hidden_size = hidden_size # hidden state\n",
    "        self.seq_length = seq_length # sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True) # lstm module\n",
    "        self.fc =  nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=device) # hidden state\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=device) # internal state\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # lstm with input, hidden, and internal state\n",
    "        hn = hn[num_layers-1] # reshaping the data for Dense layer next\n",
    "        \n",
    "        out = self.fc(hn)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947695dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 200\n",
    "batch_size = 20\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = 9\n",
    "hidden_size = 300\n",
    "num_layers = 2\n",
    "seq_length = 5\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74587e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM1(\n",
      "  (lstm): LSTM(9, 300, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=300, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainset = TrainSet(X_train_final, y_train)\n",
    "testset = TrainSet(X_test_final, y_test)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size, shuffle = True)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size, shuffle = True)\n",
    "\n",
    "model = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa037e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check_for_batch(labels, preds, batch_size):\n",
    "    total_acc = 0\n",
    "    for i in range(batch_size):        \n",
    "        total_acc += accuracy_check(labels[i], preds[i])\n",
    "    return total_acc/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ed3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_train(model, trainloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch, (inputs, labels) in enumerate(trainLoader):\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.to(device)   \n",
    "            labels = labels.to(device = device, dtype = torch.int64)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = accuracy_check_for_batch(labels, preds, inputs.size()[0])\n",
    "            total_acc += acc\n",
    "            total_loss += loss.cpu().item()\n",
    "        \n",
    "    return total_acc/(batch+1), total_loss/(batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec60d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(label, pred):\n",
    "    ims = [label, pred]\n",
    "    np_ims = []\n",
    "    for item in ims:\n",
    "        item = item.cpu().numpy()\n",
    "        np_ims.append(item)\n",
    "    compare = np.equal(np_ims[0], np_ims[1])\n",
    "    accuracy = np.sum(compare)\n",
    "    return accuracy / len(np_ims[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f03f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainLoader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainLoader): # for one batch\n",
    "        current_loss = 0.0\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device=device, dtype=torch.int64)\n",
    "        \n",
    "        \n",
    "        criterion = criterion\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "356d88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(model, valLoader, criterion, device):\n",
    "    total_val_loss=0\n",
    "    total_val_acc=0\n",
    "    for batch, (inputs, labels) in enumerate(valLoader): # for one batch\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device=device, dtype=torch.int64)\n",
    "        \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "        \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                acc = accuracy_check_for_batch(labels, preds, inputs.size()[0])\n",
    "                total_val_acc += acc\n",
    "                total_val_loss += loss.cpu().item()\n",
    "                \n",
    "                \n",
    "    return total_val_acc/(batch+1), total_val_loss/(batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ca512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred(model, finalLoader, device):\n",
    "    f = open('.csv','w', newline='')\n",
    "    for i, (inputs, labels) in enumerate(finalLoader):\n",
    "        with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device=device, dtype=torch.int64)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                wr = csv.writer(f)\n",
    "                wr.writerow([inputs[0][0][0], inputs[0][0][1], inputs[0][0][2], inputs[0][0][3], inputs[0][0][4], inputs[0][0][5], inputs[0][0][6], inputs[0][0][7], inputs[0][0][8], inputs[0][1][0], inputs[0][1][1], inputs[0][1][2], inputs[0][1][3], inputs[0][1][4], inputs[0][1][5], inputs[0][1][6], inputs[0][1][7], inputs[0][1][8], inputs[0][2][0], inputs[0][2][1], inputs[0][2][2], inputs[0][2][3], inputs[0][2][4], inputs[0][2][5], inputs[0][2][6], inputs[0][2][7], inputs[0][2][8], inputs[0][3][0], inputs[0][3][1], inputs[0][3][2], inputs[0][3][3], inputs[0][3][4], inputs[0][3][5], inputs[0][3][6], inputs[0][3][7], inputs[0][3][8], int(inputs[0][4][0]), float(inputs[0][4][1]), float(inputs[0][4][2]), float(inputs[0][4][3]), int(inputs[0][4][4]), int(inputs[0][4][5]), int(inputs[0][4][6]), int(inputs[0][4][7]), int(inputs[0][4][8]), int(labels[0]), int(preds[0])])\n",
    "                \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164cf267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "epoch : 1     train loss : 1.15838         train acc : 0.65991   \n",
      "epoch : 1     val loss : 1.16269           val acc : 0.65364   \n",
      "\n",
      "epoch : 2     train loss : 0.92554         train acc : 0.68111   \n",
      "epoch : 2     val loss : 0.91237           val acc : 0.67273   \n",
      "\n",
      "epoch : 3     train loss : 0.79592         train acc : 0.71889   \n",
      "epoch : 3     val loss : 0.79572           val acc : 0.69909   \n",
      "\n",
      "epoch : 4     train loss : 0.74214         train acc : 0.76060   \n",
      "epoch : 4     val loss : 0.72764           val acc : 0.76545   \n",
      "\n",
      "epoch : 5     train loss : 0.69583         train acc : 0.76636   \n",
      "epoch : 5     val loss : 0.69004           val acc : 0.76000   \n",
      "\n",
      "epoch : 6     train loss : 0.67673         train acc : 0.78041   \n",
      "epoch : 6     val loss : 0.67078           val acc : 0.76727   \n",
      "\n",
      "epoch : 7     train loss : 0.65172         train acc : 0.79171   \n",
      "epoch : 7     val loss : 0.65484           val acc : 0.78545   \n",
      "\n",
      "epoch : 8     train loss : 0.65406         train acc : 0.76682   \n",
      "epoch : 8     val loss : 0.65551           val acc : 0.74818   \n",
      "\n",
      "epoch : 9     train loss : 0.63195         train acc : 0.79263   \n",
      "epoch : 9     val loss : 0.62838           val acc : 0.78455   \n",
      "\n",
      "epoch : 10    train loss : 0.63964         train acc : 0.79885   \n",
      "epoch : 10    val loss : 0.63057           val acc : 0.79818   \n",
      "\n",
      "epoch : 11    train loss : 0.60950         train acc : 0.79770   \n",
      "epoch : 11    val loss : 0.61080           val acc : 0.78818   \n",
      "\n",
      "epoch : 12    train loss : 0.62886         train acc : 0.79124   \n",
      "epoch : 12    val loss : 0.67232           val acc : 0.77000   \n",
      "\n",
      "epoch : 13    train loss : 0.61707         train acc : 0.80507   \n",
      "epoch : 13    val loss : 0.63140           val acc : 0.79000   \n",
      "\n",
      "epoch : 14    train loss : 0.60137         train acc : 0.80230   \n",
      "epoch : 14    val loss : 0.62349           val acc : 0.78636   \n",
      "\n",
      "epoch : 15    train loss : 0.59873         train acc : 0.80691   \n",
      "epoch : 15    val loss : 0.59606           val acc : 0.79909   \n",
      "\n",
      "epoch : 16    train loss : 0.58387         train acc : 0.81659   \n",
      "epoch : 16    val loss : 0.62701           val acc : 0.79182   \n",
      "\n",
      "epoch : 17    train loss : 0.61966         train acc : 0.80760   \n",
      "epoch : 17    val loss : 0.68300           val acc : 0.77455   \n",
      "\n",
      "epoch : 18    train loss : 0.59112         train acc : 0.80138   \n",
      "epoch : 18    val loss : 0.59313           val acc : 0.79727   \n",
      "\n",
      "epoch : 19    train loss : 0.58024         train acc : 0.81221   \n",
      "epoch : 19    val loss : 0.59987           val acc : 0.80636   \n",
      "\n",
      "epoch : 20    train loss : 0.58152         train acc : 0.80553   \n",
      "epoch : 20    val loss : 0.59094           val acc : 0.78636   \n",
      "\n",
      "epoch : 21    train loss : 0.60817         train acc : 0.81636   \n",
      "epoch : 21    val loss : 0.65090           val acc : 0.78273   \n",
      "\n",
      "epoch : 22    train loss : 0.57528         train acc : 0.81267   \n",
      "epoch : 22    val loss : 0.60986           val acc : 0.78545   \n",
      "\n",
      "epoch : 23    train loss : 0.57212         train acc : 0.81567   \n",
      "epoch : 23    val loss : 0.60197           val acc : 0.78818   \n",
      "\n",
      "epoch : 24    train loss : 0.58323         train acc : 0.81406   \n",
      "epoch : 24    val loss : 0.60375           val acc : 0.80000   \n",
      "\n",
      "epoch : 25    train loss : 0.56151         train acc : 0.81751   \n",
      "epoch : 25    val loss : 0.59602           val acc : 0.80545   \n",
      "\n",
      "epoch : 26    train loss : 0.55796         train acc : 0.81659   \n",
      "epoch : 26    val loss : 0.59293           val acc : 0.79727   \n",
      "\n",
      "epoch : 27    train loss : 0.57325         train acc : 0.80806   \n",
      "epoch : 27    val loss : 0.59797           val acc : 0.79000   \n",
      "\n",
      "epoch : 28    train loss : 0.56618         train acc : 0.81106   \n",
      "epoch : 28    val loss : 0.60640           val acc : 0.79091   \n",
      "\n",
      "epoch : 29    train loss : 0.54903         train acc : 0.82258   \n",
      "epoch : 29    val loss : 0.63383           val acc : 0.78091   \n",
      "\n",
      "epoch : 30    train loss : 0.55244         train acc : 0.81567   \n",
      "epoch : 30    val loss : 0.59390           val acc : 0.78818   \n",
      "\n",
      "epoch : 31    train loss : 0.54449         train acc : 0.81751   \n",
      "epoch : 31    val loss : 0.59444           val acc : 0.78545   \n",
      "\n",
      "epoch : 32    train loss : 0.55333         train acc : 0.82074   \n",
      "epoch : 32    val loss : 0.58964           val acc : 0.79455   \n",
      "\n",
      "epoch : 33    train loss : 0.53383         train acc : 0.82581   \n",
      "epoch : 33    val loss : 0.57915           val acc : 0.79182   \n",
      "\n",
      "epoch : 34    train loss : 0.53098         train acc : 0.82258   \n",
      "epoch : 34    val loss : 0.58329           val acc : 0.78636   \n",
      "\n",
      "epoch : 35    train loss : 0.53792         train acc : 0.81751   \n",
      "epoch : 35    val loss : 0.58139           val acc : 0.78909   \n",
      "\n",
      "epoch : 36    train loss : 0.55529         train acc : 0.81267   \n",
      "epoch : 36    val loss : 0.61091           val acc : 0.78545   \n",
      "\n",
      "epoch : 37    train loss : 0.56980         train acc : 0.82051   \n",
      "epoch : 37    val loss : 0.60398           val acc : 0.80091   \n",
      "\n",
      "epoch : 38    train loss : 0.52695         train acc : 0.82696   \n",
      "epoch : 38    val loss : 0.58398           val acc : 0.79909   \n",
      "\n",
      "epoch : 39    train loss : 0.52745         train acc : 0.82604   \n",
      "epoch : 39    val loss : 0.57435           val acc : 0.80545   \n",
      "\n",
      "epoch : 40    train loss : 0.52259         train acc : 0.82512   \n",
      "epoch : 40    val loss : 0.58352           val acc : 0.80000   \n",
      "\n",
      "epoch : 41    train loss : 0.52220         train acc : 0.82350   \n",
      "epoch : 41    val loss : 0.57320           val acc : 0.80273   \n",
      "\n",
      "epoch : 42    train loss : 0.53204         train acc : 0.82120   \n",
      "epoch : 42    val loss : 0.60374           val acc : 0.78636   \n",
      "\n",
      "epoch : 43    train loss : 0.53548         train acc : 0.82581   \n",
      "epoch : 43    val loss : 0.60713           val acc : 0.79273   \n",
      "\n",
      "epoch : 44    train loss : 0.51388         train acc : 0.82465   \n",
      "epoch : 44    val loss : 0.57332           val acc : 0.80091   \n",
      "\n",
      "epoch : 45    train loss : 0.51882         train acc : 0.82488   \n",
      "epoch : 45    val loss : 0.57191           val acc : 0.80273   \n",
      "\n",
      "epoch : 46    train loss : 0.51603         train acc : 0.82765   \n",
      "epoch : 46    val loss : 0.60878           val acc : 0.79818   \n",
      "\n",
      "epoch : 47    train loss : 0.51040         train acc : 0.82465   \n",
      "epoch : 47    val loss : 0.57624           val acc : 0.79636   \n",
      "\n",
      "epoch : 48    train loss : 0.50893         train acc : 0.82857   \n",
      "epoch : 48    val loss : 0.57426           val acc : 0.80182   \n",
      "\n",
      "epoch : 49    train loss : 0.50792         train acc : 0.82834   \n",
      "epoch : 49    val loss : 0.56234           val acc : 0.80636   \n",
      "\n",
      "epoch : 50    train loss : 0.50171         train acc : 0.83065   \n",
      "epoch : 50    val loss : 0.57262           val acc : 0.79909   \n",
      "\n",
      "epoch : 51    train loss : 0.50835         train acc : 0.82995   \n",
      "epoch : 51    val loss : 0.57443           val acc : 0.80455   \n",
      "\n",
      "epoch : 52    train loss : 0.49487         train acc : 0.83134   \n",
      "epoch : 52    val loss : 0.57595           val acc : 0.79455   \n",
      "\n",
      "epoch : 53    train loss : 0.49437         train acc : 0.83433   \n",
      "epoch : 53    val loss : 0.57124           val acc : 0.80091   \n",
      "\n",
      "epoch : 54    train loss : 0.52363         train acc : 0.83733   \n",
      "epoch : 54    val loss : 0.62580           val acc : 0.80000   \n",
      "\n",
      "epoch : 55    train loss : 0.53022         train acc : 0.82097   \n",
      "epoch : 55    val loss : 0.62153           val acc : 0.78364   \n",
      "\n",
      "epoch : 56    train loss : 0.50530         train acc : 0.83088   \n",
      "epoch : 56    val loss : 0.58196           val acc : 0.80091   \n",
      "\n",
      "epoch : 57    train loss : 0.48847         train acc : 0.82834   \n",
      "epoch : 57    val loss : 0.57036           val acc : 0.80364   \n",
      "\n",
      "epoch : 58    train loss : 0.55042         train acc : 0.82396   \n",
      "epoch : 58    val loss : 0.62446           val acc : 0.79727   \n",
      "\n",
      "epoch : 59    train loss : 0.51262         train acc : 0.81982   \n",
      "epoch : 59    val loss : 0.58373           val acc : 0.79636   \n",
      "\n",
      "epoch : 60    train loss : 0.49907         train acc : 0.82903   \n",
      "epoch : 60    val loss : 0.59305           val acc : 0.78909   \n",
      "\n",
      "epoch : 61    train loss : 0.50740         train acc : 0.83687   \n",
      "epoch : 61    val loss : 0.59451           val acc : 0.80364   \n",
      "\n",
      "epoch : 62    train loss : 0.49870         train acc : 0.83687   \n",
      "epoch : 62    val loss : 0.58941           val acc : 0.80182   \n",
      "\n",
      "epoch : 63    train loss : 0.48822         train acc : 0.83341   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 63    val loss : 0.57660           val acc : 0.79909   \n",
      "\n",
      "epoch : 64    train loss : 0.47051         train acc : 0.83664   \n",
      "epoch : 64    val loss : 0.57679           val acc : 0.80000   \n",
      "\n",
      "epoch : 65    train loss : 0.47967         train acc : 0.83525   \n",
      "epoch : 65    val loss : 0.56701           val acc : 0.80545   \n",
      "\n",
      "epoch : 66    train loss : 0.47272         train acc : 0.83664   \n",
      "epoch : 66    val loss : 0.56175           val acc : 0.80545   \n",
      "\n",
      "epoch : 67    train loss : 0.48356         train acc : 0.83180   \n",
      "epoch : 67    val loss : 0.58039           val acc : 0.80818   \n",
      "\n",
      "epoch : 68    train loss : 0.48141         train acc : 0.83341   \n",
      "epoch : 68    val loss : 0.58291           val acc : 0.80273   \n",
      "\n",
      "epoch : 69    train loss : 0.45746         train acc : 0.84032   \n",
      "epoch : 69    val loss : 0.56084           val acc : 0.79909   \n",
      "\n",
      "epoch : 70    train loss : 0.49055         train acc : 0.83710   \n",
      "epoch : 70    val loss : 0.59200           val acc : 0.79455   \n",
      "\n",
      "epoch : 71    train loss : 0.56281         train acc : 0.80092   \n",
      "epoch : 71    val loss : 0.66923           val acc : 0.77364   \n",
      "\n",
      "epoch : 72    train loss : 0.46295         train acc : 0.84194   \n",
      "epoch : 72    val loss : 0.57848           val acc : 0.80273   \n",
      "\n",
      "epoch : 73    train loss : 0.45328         train acc : 0.84447   \n",
      "epoch : 73    val loss : 0.56361           val acc : 0.80364   \n",
      "\n",
      "epoch : 74    train loss : 0.46098         train acc : 0.83871   \n",
      "epoch : 74    val loss : 0.57551           val acc : 0.80455   \n",
      "\n",
      "epoch : 75    train loss : 0.45705         train acc : 0.84171   \n",
      "epoch : 75    val loss : 0.57707           val acc : 0.79909   \n",
      "\n",
      "epoch : 76    train loss : 0.47323         train acc : 0.83756   \n",
      "epoch : 76    val loss : 0.58309           val acc : 0.79364   \n",
      "\n",
      "epoch : 77    train loss : 0.45359         train acc : 0.84470   \n",
      "epoch : 77    val loss : 0.56713           val acc : 0.80636   \n",
      "\n",
      "epoch : 78    train loss : 0.49117         train acc : 0.82903   \n",
      "epoch : 78    val loss : 0.59859           val acc : 0.80000   \n",
      "\n",
      "epoch : 79    train loss : 0.44227         train acc : 0.84539   \n",
      "epoch : 79    val loss : 0.57527           val acc : 0.79727   \n",
      "\n",
      "epoch : 80    train loss : 0.44258         train acc : 0.84631   \n",
      "epoch : 80    val loss : 0.56869           val acc : 0.80091   \n",
      "\n",
      "epoch : 81    train loss : 0.45966         train acc : 0.83986   \n",
      "epoch : 81    val loss : 0.57082           val acc : 0.80364   \n",
      "\n",
      "epoch : 82    train loss : 0.44274         train acc : 0.84424   \n",
      "epoch : 82    val loss : 0.56014           val acc : 0.80727   \n",
      "\n",
      "epoch : 83    train loss : 0.43282         train acc : 0.84677   \n",
      "epoch : 83    val loss : 0.56434           val acc : 0.80273   \n",
      "\n",
      "epoch : 84    train loss : 0.46405         train acc : 0.84447   \n",
      "epoch : 84    val loss : 0.60474           val acc : 0.78455   \n",
      "\n",
      "epoch : 85    train loss : 0.45385         train acc : 0.84124   \n",
      "epoch : 85    val loss : 0.60230           val acc : 0.78818   \n",
      "\n",
      "epoch : 86    train loss : 0.42521         train acc : 0.85207   \n",
      "epoch : 86    val loss : 0.55762           val acc : 0.80636   \n",
      "\n",
      "epoch : 87    train loss : 0.43306         train acc : 0.84954   \n",
      "epoch : 87    val loss : 0.58228           val acc : 0.80182   \n",
      "\n",
      "epoch : 88    train loss : 0.49216         train acc : 0.82535   \n",
      "epoch : 88    val loss : 0.61386           val acc : 0.79364   \n",
      "\n",
      "epoch : 89    train loss : 0.42189         train acc : 0.85023   \n",
      "epoch : 89    val loss : 0.57958           val acc : 0.80000   \n",
      "\n",
      "epoch : 90    train loss : 0.42938         train acc : 0.85184   \n",
      "epoch : 90    val loss : 0.57894           val acc : 0.78909   \n",
      "\n",
      "epoch : 91    train loss : 0.46046         train acc : 0.83917   \n",
      "epoch : 91    val loss : 0.61114           val acc : 0.78364   \n",
      "\n",
      "epoch : 92    train loss : 0.42222         train acc : 0.85138   \n",
      "epoch : 92    val loss : 0.59357           val acc : 0.78909   \n",
      "\n",
      "epoch : 93    train loss : 0.44519         train acc : 0.84977   \n",
      "epoch : 93    val loss : 0.59684           val acc : 0.79727   \n",
      "\n",
      "epoch : 94    train loss : 0.41880         train acc : 0.85023   \n",
      "epoch : 94    val loss : 0.56487           val acc : 0.81091   \n",
      "\n",
      "\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\\n\")\n",
    "for epoch in range(epoches):\n",
    "    \n",
    "    train_model(model, trainLoader, criterion, optimizer, scheduler, device)\n",
    "    train_acc, train_loss = get_loss_train(model, trainLoader, criterion, device)\n",
    "    print(\"epoch : {:<5} train loss : {:<15.5f} train acc : {:<10.5f}\".format(epoch+1, train_loss, train_acc))\n",
    "    \n",
    "    val_acc, val_loss = val_model(model, testLoader, criterion, device)\n",
    "    print(\"epoch : {:<5} val loss : {:<17.5f} val acc : {:<10.5f}\\n\".format(epoch+1, val_loss, val_acc))\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    \n",
    "print(\"\\nTraining Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ace588b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLoader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle = False)\n",
    "print_pred(model, finalLoader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20aefeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(epoch+1), history['train_loss'], label='Loss', color='red')\n",
    "plt.plot(range(epoch+1), history['val_loss'], label='Loss', color='blue')\n",
    "\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(epoch+1), history['train_acc'], label='Accuracy', color='red')\n",
    "plt.plot(range(epoch+1), history['val_acc'], label='Accuracy', color='blue')\n",
    "\n",
    "plt.title('Accuracy history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
