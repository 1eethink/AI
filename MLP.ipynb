{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "062f56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a608b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True  Use << CUDA >>\n",
      "PyTorch Version: 1.7.1+cu110\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('CUDA:', torch.cuda.is_available(), ' Use << {} >>'.format(device.upper()))\n",
    "print('PyTorch Version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4dcf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "\n",
    "        dataframe = pd.read_csv(file_name)\n",
    "        x = dataframe.iloc[:,0:9].values # inputs\n",
    "        y = dataframe.iloc[:, 9].values # labels\n",
    "        z = dataframe.iloc[:, 10:15].values # details\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.x[idx], self.y[idx], self.z[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125432ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "\n",
    "        dataframe = pd.read_csv(file_name)\n",
    "        \n",
    "        x = dataframe.iloc[:,0:9].values # inputs\n",
    "        y = dataframe.iloc[:, 9].values # labels\n",
    "        y = (y-100)/100 # labels must start at 0 so adjust this to your data\n",
    "        z = dataframe.iloc[:, 10:15].values # details\n",
    "        \n",
    "        #converting to torch tensors\n",
    "        self.x = torch.tensor(x, dtype=torch.float32) \n",
    "        self.y = torch.tensor(y, dtype=torch.int32)\n",
    "        self.z = torch.tensor(z, dtype=torch.int32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.x[idx], self.y[idx], self.z[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6dc9bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data looks like\n",
      "[[ 2.00000000e+02  4.78722035e+00 -7.16397610e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 2.00000000e+02  4.26964719e+00  2.12739533e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 2.00000000e+02  5.21402244e+00 -2.63581875e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 3.00000000e+02  4.98698533e+00  3.36784830e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 4.00000000e+02  4.48742140e+00  6.35409590e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 2.00000000e+02  4.69049467e+00  1.32605150e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]]\n",
      "[200 200 200 ... 300 400 200]\n",
      "\n",
      "Total Data Length: 18261\n",
      "X_train shape: (12782, 9)\n",
      "X_val shape: (2739, 9)\n",
      "X_test shape: (2740, 9)\n",
      "y_train shape: (12782,)\n",
      "y_val shape: (2739,)\n",
      "y_test shape: (2740,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.chdir(\"C:\\\\\") # adjust this to your file directory\n",
    "input_data = CSVDataset('.csv') # adjust this to your file name\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTotal Data Length:\", len(input_data))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(input_data.x, input_data.y, input_data.z, test_size=0.3, shuffle = True, random_state=42)\n",
    "X_val, X_test, y_val, y_test, z_val, z_test = train_test_split(X_test, y_test, z_test, test_size=0.5, shuffle = True, random_state = 3)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "# Save train data set\n",
    "f = open('.csv','w', newline='')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    wr.writerow([(X_train[i][0]/100)-5.5, X_train[i][1], X_train[i][2], X_train[i][3], X_train[i][4], X_train[i][5], X_train[i][6], X_train[i][7], X_train[i][8], y_train[i] , z_train[i][0], z_train[i][1], z_train[i][2], z_train[i][3], z_train[i][4]])\n",
    "    # you can change the data\n",
    "    \n",
    "f.close()\n",
    "\n",
    "# Save validation data set\n",
    "f = open('.csv','w', newline='')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    wr.writerow([(X_val[i][0]/100)-5.5, X_val[i][1], X_val[i][2], X_val[i][3], X_val[i][4], X_val[i][5], X_val[i][6], X_val[i][7], X_val[i][8], y_val[i], z_val[i][0], z_val[i][1], z_val[i][2], z_val[i][3], z_val[i][4]])\n",
    "    \n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "# Save test data set\n",
    "f = open('.csv','w', newline='')\n",
    "wr = csv.writer(f)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    wr.writerow([(X_test[i][0]/100)-5.5, X_test[i][1], X_test[i][2], X_test[i][3], X_test[i][4], X_test[i][5], X_test[i][6], X_test[i][7], X_test[i][8], y_test[i], z_test[i][0], z_test[i][1], z_test[i][2], z_test[i][3], z_test[i][4]])\n",
    "    \n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f52dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_input):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.act = ReLU()\n",
    "        \n",
    "        self.hidden1 = Linear(n_input, 100).to(device)\n",
    "        \n",
    "        self.hidden2 = Linear(100, 300).to(device)\n",
    "        \n",
    "        self.hidden3 = Linear(300, 100).to(device)\n",
    "        \n",
    "        self.hiddenfinal = Linear(100, 10).to(device)\n",
    "\n",
    "    # this example has 3 hidden layers\n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.hidden1(X)\n",
    "        X = self.act(X)\n",
    "        \n",
    "        X = self.hidden2(X)\n",
    "        X = self.act(X)\n",
    "        \n",
    "        X = self.hidden3(X)\n",
    "        X = self.act(X)\n",
    "        \n",
    "        X = self.hiddenfinal(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9602aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 100\n",
    "batch_size = 40\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d253dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\\")\n",
    "trainset = TrainDataset('.csv') # adjust this to your file name\n",
    "valset = TrainDataset('.csv') # adjust this to your file name\n",
    "testset = TrainDataset('.csv') # adjust this to your file name\n",
    "\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size, shuffle = True)\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size, shuffle = True)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size, shuffle = True)\n",
    "\n",
    "model = MLP(9)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[], 'test_loss':[], 'test_acc':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896c0d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check_for_batch(labels, preds, batch_size):\n",
    "    total_acc = 0\n",
    "    for i in range(batch_size):        \n",
    "        total_acc += accuracy_check(labels[i], preds[i])\n",
    "    return total_acc/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dff125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_train(model, trainloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch, (inputs, labels, details) in enumerate(trainLoader):\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device = device, dtype = torch.int64)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            acc = accuracy_check_for_batch(labels, preds, inputs.size()[0])\n",
    "            total_acc += acc\n",
    "            total_loss += loss.cpu().item()\n",
    "        \n",
    "    return total_acc/(batch+1), total_loss/(batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbc5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(label, pred):\n",
    "    ims = [label, pred]\n",
    "    np_ims = []\n",
    "    for item in ims:\n",
    "        item = item.cpu().numpy()\n",
    "        np_ims.append(item)\n",
    "    compare = np.equal(np_ims[0], np_ims[1])\n",
    "    accuracy = np.sum(compare)\n",
    "    return accuracy / len(np_ims[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12695207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainLoader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    \n",
    "    for i, (inputs, labels, details) in enumerate(trainLoader): # for one batch\n",
    "        current_loss = 0.0\n",
    "        \n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device=device, dtype=torch.int64)\n",
    "        \n",
    "        \n",
    "        criterion = criterion.cuda()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5db713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_model(model, valLoader, criterion, device):\n",
    "    total_val_loss=0\n",
    "    total_val_acc=0\n",
    "    for batch, (inputs, labels, details) in enumerate(valLoader): # for one batch\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device=device, dtype=torch.int64)\n",
    "        \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "        \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                acc = accuracy_check_for_batch(labels, preds, inputs.size()[0])\n",
    "                total_val_acc += acc\n",
    "                total_val_loss += loss.cpu().item()\n",
    "                \n",
    "            \n",
    "    \n",
    "                \n",
    "                \n",
    "    return total_val_acc/(batch+1), total_val_loss/(batch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691af376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred(model, finalLoader, device):\n",
    "    f = open('.csv','w', newline='') # adjust this to your file name\n",
    "    for i, (inputs, labels, details) in enumerate(finalLoader):\n",
    "        with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device=device, dtype=torch.int64)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                wr = csv.writer(f)\n",
    "                wr.writerow([inputs[0][0], inputs[0][1], inputs[0][2], inputs[0][3], int(inputs[0][4]), int(inputs[0][5]), int(inputs[0][6]), int(inputs[0][7]), int(inputs[0][8]),  int(labels[0]), int(details[0][0]), int(details[0][1]), int(details[0][2]), int(details[0][3]), int(details[0][4]) ,int(preds[0])])\n",
    "            \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38708c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "\n",
      "epoch : 1     train loss : 0.23781         train acc : 0.92563   \n",
      "epoch : 1     val loss : 0.24461           val acc : 0.92520   \n",
      "epoch : 1     test loss : 0.21599          test acc : 0.93478   \n",
      "\n",
      "epoch : 2     train loss : 0.22271         train acc : 0.93352   \n",
      "epoch : 2     val loss : 0.21609           val acc : 0.93297   \n",
      "epoch : 2     test loss : 0.20254          test acc : 0.93514   \n",
      "\n",
      "epoch : 3     train loss : 0.21722         train acc : 0.93360   \n",
      "epoch : 3     val loss : 0.21364           val acc : 0.93506   \n",
      "epoch : 3     test loss : 0.19354          test acc : 0.94167   \n",
      "\n",
      "epoch : 4     train loss : 0.20393         train acc : 0.92791   \n",
      "epoch : 4     val loss : 0.20664           val acc : 0.93035   \n",
      "epoch : 4     test loss : 0.18891          test acc : 0.93514   \n",
      "\n",
      "epoch : 5     train loss : 0.19348         train acc : 0.93416   \n",
      "epoch : 5     val loss : 0.19963           val acc : 0.93571   \n",
      "epoch : 5     test loss : 0.18336          test acc : 0.93902   \n",
      "\n",
      "epoch : 6     train loss : 0.20911         train acc : 0.93423   \n",
      "epoch : 6     val loss : 0.21259           val acc : 0.93470   \n",
      "epoch : 6     test loss : 0.19452          test acc : 0.93768   \n",
      "\n",
      "epoch : 7     train loss : 0.19244         train acc : 0.93539   \n",
      "epoch : 7     val loss : 0.20185           val acc : 0.93571   \n",
      "epoch : 7     test loss : 0.17822          test acc : 0.94127   \n",
      "\n",
      "epoch : 8     train loss : 0.20217         train acc : 0.93580   \n",
      "epoch : 8     val loss : 0.20936           val acc : 0.93961   \n",
      "epoch : 8     test loss : 0.18802          test acc : 0.94304   \n",
      "\n",
      "epoch : 9     train loss : 0.18085         train acc : 0.93859   \n",
      "epoch : 9     val loss : 0.19048           val acc : 0.94094   \n",
      "epoch : 9     test loss : 0.17012          test acc : 0.94453   \n",
      "\n",
      "epoch : 10    train loss : 0.17814         train acc : 0.93760   \n",
      "epoch : 10    val loss : 0.18408           val acc : 0.94122   \n",
      "epoch : 10    test loss : 0.16507          test acc : 0.94409   \n",
      "\n",
      "epoch : 11    train loss : 0.17998         train acc : 0.93643   \n",
      "epoch : 11    val loss : 0.18599           val acc : 0.93724   \n",
      "epoch : 11    test loss : 0.16681          test acc : 0.94235   \n",
      "\n",
      "epoch : 12    train loss : 0.17775         train acc : 0.93830   \n",
      "epoch : 12    val loss : 0.18898           val acc : 0.93824   \n",
      "epoch : 12    test loss : 0.16743          test acc : 0.94275   \n",
      "\n",
      "epoch : 13    train loss : 0.17681         train acc : 0.94032   \n",
      "epoch : 13    val loss : 0.18404           val acc : 0.94122   \n",
      "epoch : 13    test loss : 0.15969          test acc : 0.94561   \n",
      "\n",
      "epoch : 14    train loss : 0.17310         train acc : 0.93969   \n",
      "epoch : 14    val loss : 0.18444           val acc : 0.93833   \n",
      "epoch : 14    test loss : 0.16357          test acc : 0.93902   \n",
      "\n",
      "epoch : 15    train loss : 0.17434         train acc : 0.93914   \n",
      "epoch : 15    val loss : 0.18522           val acc : 0.94239   \n",
      "epoch : 15    test loss : 0.16466          test acc : 0.94308   \n",
      "\n",
      "epoch : 16    train loss : 0.17355         train acc : 0.93930   \n",
      "epoch : 16    val loss : 0.17947           val acc : 0.94022   \n",
      "epoch : 16    test loss : 0.16645          test acc : 0.94195   \n",
      "\n",
      "epoch : 17    train loss : 0.18011         train acc : 0.93877   \n",
      "epoch : 17    val loss : 0.19069           val acc : 0.93833   \n",
      "epoch : 17    test loss : 0.17495          test acc : 0.94449   \n",
      "\n",
      "epoch : 18    train loss : 0.16324         train acc : 0.94011   \n",
      "epoch : 18    val loss : 0.17329           val acc : 0.94304   \n",
      "epoch : 18    test loss : 0.15753          test acc : 0.94123   \n",
      "\n",
      "epoch : 19    train loss : 0.17299         train acc : 0.93580   \n",
      "epoch : 19    val loss : 0.18539           val acc : 0.93949   \n",
      "epoch : 19    test loss : 0.17191          test acc : 0.93619   \n",
      "\n",
      "epoch : 20    train loss : 0.16657         train acc : 0.94079   \n",
      "epoch : 20    val loss : 0.17483           val acc : 0.94014   \n",
      "epoch : 20    test loss : 0.16116          test acc : 0.94094   \n",
      "\n",
      "epoch : 21    train loss : 0.16739         train acc : 0.94048   \n",
      "epoch : 21    val loss : 0.18092           val acc : 0.94058   \n",
      "epoch : 21    test loss : 0.16734          test acc : 0.94340   \n",
      "\n",
      "epoch : 22    train loss : 0.16160         train acc : 0.94102   \n",
      "epoch : 22    val loss : 0.17914           val acc : 0.94042   \n",
      "epoch : 22    test loss : 0.15486          test acc : 0.94521   \n",
      "\n",
      "epoch : 23    train loss : 0.15668         train acc : 0.94259   \n",
      "epoch : 23    val loss : 0.17389           val acc : 0.94368   \n",
      "epoch : 23    test loss : 0.15100          test acc : 0.94598   \n",
      "\n",
      "epoch : 24    train loss : 0.16175         train acc : 0.94305   \n",
      "epoch : 24    val loss : 0.17904           val acc : 0.94521   \n",
      "epoch : 24    test loss : 0.15750          test acc : 0.94529   \n",
      "\n",
      "epoch : 25    train loss : 0.15893         train acc : 0.94236   \n",
      "epoch : 25    val loss : 0.17436           val acc : 0.94348   \n",
      "epoch : 25    test loss : 0.15364          test acc : 0.94674   \n",
      "\n",
      "epoch : 26    train loss : 0.16208         train acc : 0.94234   \n",
      "epoch : 26    val loss : 0.18185           val acc : 0.94114   \n",
      "epoch : 26    test loss : 0.15728          test acc : 0.94706   \n",
      "\n",
      "epoch : 27    train loss : 0.15827         train acc : 0.94227   \n",
      "epoch : 27    val loss : 0.17433           val acc : 0.93752   \n",
      "epoch : 27    test loss : 0.15799          test acc : 0.94239   \n",
      "\n",
      "epoch : 28    train loss : 0.15209         train acc : 0.94469   \n",
      "epoch : 28    val loss : 0.17205           val acc : 0.94304   \n",
      "epoch : 28    test loss : 0.15262          test acc : 0.94674   \n",
      "\n",
      "epoch : 29    train loss : 0.15723         train acc : 0.94125   \n",
      "epoch : 29    val loss : 0.18000           val acc : 0.93808   \n",
      "epoch : 29    test loss : 0.15689          test acc : 0.94275   \n",
      "\n",
      "epoch : 30    train loss : 0.15434         train acc : 0.94375   \n",
      "epoch : 30    val loss : 0.17828           val acc : 0.93986   \n",
      "epoch : 30    test loss : 0.15474          test acc : 0.94891   \n",
      "\n",
      "epoch : 31    train loss : 0.15212         train acc : 0.94393   \n",
      "epoch : 31    val loss : 0.17461           val acc : 0.94267   \n",
      "epoch : 31    test loss : 0.15425          test acc : 0.94409   \n",
      "\n",
      "epoch : 32    train loss : 0.15366         train acc : 0.94454   \n",
      "epoch : 32    val loss : 0.17197           val acc : 0.93941   \n",
      "epoch : 32    test loss : 0.15765          test acc : 0.94634   \n",
      "\n",
      "epoch : 33    train loss : 0.15164         train acc : 0.94587   \n",
      "epoch : 33    val loss : 0.17808           val acc : 0.94267   \n",
      "epoch : 33    test loss : 0.16573          test acc : 0.94155   \n",
      "\n",
      "epoch : 34    train loss : 0.15027         train acc : 0.94602   \n",
      "epoch : 34    val loss : 0.17746           val acc : 0.94014   \n",
      "epoch : 34    test loss : 0.16008          test acc : 0.94272   \n",
      "\n",
      "epoch : 35    train loss : 0.15125         train acc : 0.94259   \n",
      "epoch : 35    val loss : 0.17595           val acc : 0.93651   \n",
      "epoch : 35    test loss : 0.15472          test acc : 0.94634   \n",
      "\n",
      "epoch : 36    train loss : 0.14846         train acc : 0.94531   \n",
      "epoch : 36    val loss : 0.17620           val acc : 0.94239   \n",
      "epoch : 36    test loss : 0.15832          test acc : 0.94453   \n",
      "\n",
      "epoch : 37    train loss : 0.15181         train acc : 0.94516   \n",
      "epoch : 37    val loss : 0.18058           val acc : 0.94412   \n",
      "epoch : 37    test loss : 0.15641          test acc : 0.95145   \n",
      "\n",
      "epoch : 38    train loss : 0.15386         train acc : 0.94416   \n",
      "epoch : 38    val loss : 0.18417           val acc : 0.93724   \n",
      "epoch : 38    test loss : 0.15569          test acc : 0.94525   \n",
      "\n",
      "epoch : 39    train loss : 0.15414         train acc : 0.94602   \n",
      "epoch : 39    val loss : 0.18524           val acc : 0.94223   \n",
      "epoch : 39    test loss : 0.16572          test acc : 0.94598   \n",
      "\n",
      "epoch : 40    train loss : 0.14947         train acc : 0.94602   \n",
      "epoch : 40    val loss : 0.17864           val acc : 0.94332   \n",
      "epoch : 40    test loss : 0.16030          test acc : 0.94561   \n",
      "\n",
      "epoch : 41    train loss : 0.14292         train acc : 0.94680   \n",
      "epoch : 41    val loss : 0.17664           val acc : 0.94267   \n",
      "epoch : 41    test loss : 0.15154          test acc : 0.94634   \n",
      "\n",
      "epoch : 42    train loss : 0.14587         train acc : 0.94602   \n",
      "epoch : 42    val loss : 0.17831           val acc : 0.94042   \n",
      "epoch : 42    test loss : 0.15785          test acc : 0.94525   \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 43    train loss : 0.14405         train acc : 0.94805   \n",
      "epoch : 43    val loss : 0.17657           val acc : 0.94014   \n",
      "epoch : 43    test loss : 0.15016          test acc : 0.94561   \n",
      "\n",
      "epoch : 44    train loss : 0.14152         train acc : 0.94821   \n",
      "epoch : 44    val loss : 0.17739           val acc : 0.94143   \n",
      "epoch : 44    test loss : 0.15447          test acc : 0.94518   \n",
      "\n",
      "epoch : 45    train loss : 0.14136         train acc : 0.94907   \n",
      "epoch : 45    val loss : 0.17873           val acc : 0.94223   \n",
      "epoch : 45    test loss : 0.15646          test acc : 0.94920   \n",
      "\n",
      "epoch : 46    train loss : 0.14061         train acc : 0.94852   \n",
      "epoch : 46    val loss : 0.17683           val acc : 0.94159   \n",
      "epoch : 46    test loss : 0.15635          test acc : 0.94268   \n",
      "\n",
      "epoch : 47    train loss : 0.14903         train acc : 0.94502   \n",
      "epoch : 47    val loss : 0.18753           val acc : 0.93535   \n",
      "epoch : 47    test loss : 0.16149          test acc : 0.94264   \n",
      "\n",
      "epoch : 48    train loss : 0.14306         train acc : 0.94791   \n",
      "epoch : 48    val loss : 0.18000           val acc : 0.93897   \n",
      "epoch : 48    test loss : 0.15368          test acc : 0.94594   \n",
      "\n",
      "epoch : 49    train loss : 0.13991         train acc : 0.94790   \n",
      "epoch : 49    val loss : 0.17916           val acc : 0.93824   \n",
      "epoch : 49    test loss : 0.15378          test acc : 0.94380   \n",
      "\n",
      "epoch : 50    train loss : 0.13928         train acc : 0.94993   \n",
      "epoch : 50    val loss : 0.17948           val acc : 0.94022   \n",
      "epoch : 50    test loss : 0.15545          test acc : 0.94638   \n",
      "\n",
      "epoch : 51    train loss : 0.13759         train acc : 0.95033   \n",
      "epoch : 51    val loss : 0.18214           val acc : 0.94114   \n",
      "epoch : 51    test loss : 0.15396          test acc : 0.94746   \n",
      "\n",
      "epoch : 52    train loss : 0.13974         train acc : 0.94869   \n",
      "epoch : 52    val loss : 0.18190           val acc : 0.94179   \n",
      "epoch : 52    test loss : 0.15806          test acc : 0.94376   \n",
      "\n",
      "epoch : 53    train loss : 0.14192         train acc : 0.95080   \n",
      "epoch : 53    val loss : 0.18248           val acc : 0.94122   \n",
      "epoch : 53    test loss : 0.16068          test acc : 0.94703   \n",
      "\n",
      "epoch : 54    train loss : 0.14299         train acc : 0.94705   \n",
      "epoch : 54    val loss : 0.19163           val acc : 0.93977   \n",
      "epoch : 54    test loss : 0.16011          test acc : 0.94199   \n",
      "\n",
      "epoch : 55    train loss : 0.13875         train acc : 0.94891   \n",
      "epoch : 55    val loss : 0.18411           val acc : 0.93905   \n",
      "epoch : 55    test loss : 0.15419          test acc : 0.94601   \n",
      "\n",
      "epoch : 56    train loss : 0.13843         train acc : 0.94805   \n",
      "epoch : 56    val loss : 0.18395           val acc : 0.94086   \n",
      "epoch : 56    test loss : 0.16014          test acc : 0.94308   \n",
      "\n",
      "epoch : 57    train loss : 0.13810         train acc : 0.95024   \n",
      "epoch : 57    val loss : 0.18104           val acc : 0.94094   \n",
      "epoch : 57    test loss : 0.15654          test acc : 0.95032   \n",
      "\n",
      "epoch : 58    train loss : 0.13454         train acc : 0.95016   \n",
      "epoch : 58    val loss : 0.17991           val acc : 0.94312   \n",
      "epoch : 58    test loss : 0.15469          test acc : 0.94634   \n",
      "\n",
      "epoch : 59    train loss : 0.13382         train acc : 0.94908   \n",
      "epoch : 59    val loss : 0.18292           val acc : 0.94203   \n",
      "epoch : 59    test loss : 0.15737          test acc : 0.94348   \n",
      "\n",
      "epoch : 60    train loss : 0.14760         train acc : 0.94907   \n",
      "epoch : 60    val loss : 0.19982           val acc : 0.93708   \n",
      "epoch : 60    test loss : 0.17323          test acc : 0.94638   \n",
      "\n",
      "epoch : 61    train loss : 0.13463         train acc : 0.95031   \n",
      "epoch : 61    val loss : 0.18519           val acc : 0.94239   \n",
      "epoch : 61    test loss : 0.15945          test acc : 0.94525   \n",
      "\n",
      "epoch : 62    train loss : 0.13331         train acc : 0.95228   \n",
      "epoch : 62    val loss : 0.18395           val acc : 0.94340   \n",
      "epoch : 62    test loss : 0.15795          test acc : 0.94558   \n",
      "\n",
      "epoch : 63    train loss : 0.13148         train acc : 0.95165   \n",
      "epoch : 63    val loss : 0.18227           val acc : 0.94239   \n",
      "epoch : 63    test loss : 0.15379          test acc : 0.94851   \n",
      "\n",
      "epoch : 64    train loss : 0.13072         train acc : 0.95227   \n",
      "epoch : 64    val loss : 0.18360           val acc : 0.94187   \n",
      "epoch : 64    test loss : 0.15481          test acc : 0.94746   \n",
      "\n",
      "epoch : 65    train loss : 0.13110         train acc : 0.95204   \n",
      "epoch : 65    val loss : 0.18496           val acc : 0.94195   \n",
      "epoch : 65    test loss : 0.15434          test acc : 0.94855   \n",
      "\n",
      "epoch : 66    train loss : 0.13405         train acc : 0.95086   \n",
      "epoch : 66    val loss : 0.19065           val acc : 0.93905   \n",
      "epoch : 66    test loss : 0.15429          test acc : 0.94638   \n",
      "\n",
      "epoch : 67    train loss : 0.12973         train acc : 0.95228   \n",
      "epoch : 67    val loss : 0.18582           val acc : 0.94412   \n",
      "epoch : 67    test loss : 0.15302          test acc : 0.94783   \n",
      "\n",
      "epoch : 68    train loss : 0.13265         train acc : 0.95000   \n",
      "epoch : 68    val loss : 0.18584           val acc : 0.93969   \n",
      "epoch : 68    test loss : 0.15694          test acc : 0.94598   \n",
      "\n",
      "epoch : 69    train loss : 0.13515         train acc : 0.95119   \n",
      "epoch : 69    val loss : 0.18819           val acc : 0.93804   \n",
      "epoch : 69    test loss : 0.16134          test acc : 0.94601   \n",
      "\n",
      "epoch : 70    train loss : 0.13004         train acc : 0.95375   \n",
      "epoch : 70    val loss : 0.18802           val acc : 0.94086   \n",
      "epoch : 70    test loss : 0.15607          test acc : 0.95000   \n",
      "\n",
      "epoch : 71    train loss : 0.12735         train acc : 0.95312   \n",
      "epoch : 71    val loss : 0.18411           val acc : 0.94195   \n",
      "epoch : 71    test loss : 0.15291          test acc : 0.94706   \n",
      "\n",
      "epoch : 72    train loss : 0.12880         train acc : 0.95267   \n",
      "epoch : 72    val loss : 0.18506           val acc : 0.94195   \n",
      "epoch : 72    test loss : 0.15462          test acc : 0.94855   \n",
      "\n",
      "epoch : 73    train loss : 0.13181         train acc : 0.95180   \n",
      "epoch : 73    val loss : 0.19173           val acc : 0.94094   \n",
      "epoch : 73    test loss : 0.15920          test acc : 0.94561   \n",
      "\n",
      "epoch : 74    train loss : 0.12870         train acc : 0.95337   \n",
      "epoch : 74    val loss : 0.18764           val acc : 0.94259   \n",
      "epoch : 74    test loss : 0.15737          test acc : 0.94815   \n",
      "\n",
      "epoch : 75    train loss : 0.12951         train acc : 0.95391   \n",
      "epoch : 75    val loss : 0.19119           val acc : 0.94086   \n",
      "epoch : 75    test loss : 0.16025          test acc : 0.94884   \n",
      "\n",
      "epoch : 76    train loss : 0.12797         train acc : 0.95268   \n",
      "epoch : 76    val loss : 0.18532           val acc : 0.94078   \n",
      "epoch : 76    test loss : 0.15681          test acc : 0.94666   \n",
      "\n",
      "epoch : 77    train loss : 0.12913         train acc : 0.95195   \n",
      "epoch : 77    val loss : 0.19445           val acc : 0.93780   \n",
      "epoch : 77    test loss : 0.16191          test acc : 0.94489   \n",
      "\n",
      "epoch : 78    train loss : 0.12829         train acc : 0.95274   \n",
      "epoch : 78    val loss : 0.18863           val acc : 0.94058   \n",
      "epoch : 78    test loss : 0.15633          test acc : 0.94928   \n",
      "\n",
      "epoch : 79    train loss : 0.13066         train acc : 0.95122   \n",
      "epoch : 79    val loss : 0.19472           val acc : 0.93587   \n",
      "epoch : 79    test loss : 0.16127          test acc : 0.94743   \n",
      "\n",
      "epoch : 80    train loss : 0.12801         train acc : 0.95291   \n",
      "epoch : 80    val loss : 0.18732           val acc : 0.94050   \n",
      "epoch : 80    test loss : 0.15930          test acc : 0.94630   \n",
      "\n",
      "epoch : 81    train loss : 0.12586         train acc : 0.95376   \n",
      "epoch : 81    val loss : 0.18937           val acc : 0.94195   \n",
      "epoch : 81    test loss : 0.15764          test acc : 0.94746   \n",
      "\n",
      "epoch : 82    train loss : 0.12493         train acc : 0.95437   \n",
      "epoch : 82    val loss : 0.18970           val acc : 0.93788   \n",
      "epoch : 82    test loss : 0.16082          test acc : 0.94590   \n",
      "\n",
      "epoch : 83    train loss : 0.12435         train acc : 0.95469   \n",
      "epoch : 83    val loss : 0.18824           val acc : 0.94122   \n",
      "epoch : 83    test loss : 0.15505          test acc : 0.94746   \n",
      "\n",
      "epoch : 84    train loss : 0.12711         train acc : 0.95329   \n",
      "epoch : 84    val loss : 0.19036           val acc : 0.94022   \n",
      "epoch : 84    test loss : 0.15954          test acc : 0.94634   \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 85    train loss : 0.12485         train acc : 0.95501   \n",
      "epoch : 85    val loss : 0.18914           val acc : 0.94275   \n",
      "epoch : 85    test loss : 0.15913          test acc : 0.94855   \n",
      "\n",
      "epoch : 86    train loss : 0.12410         train acc : 0.95493   \n",
      "epoch : 86    val loss : 0.19080           val acc : 0.94086   \n",
      "epoch : 86    test loss : 0.15932          test acc : 0.94743   \n",
      "\n",
      "epoch : 87    train loss : 0.12482         train acc : 0.95416   \n",
      "epoch : 87    val loss : 0.19084           val acc : 0.94340   \n",
      "epoch : 87    test loss : 0.15672          test acc : 0.95000   \n",
      "\n",
      "epoch : 88    train loss : 0.12572         train acc : 0.95359   \n",
      "epoch : 88    val loss : 0.19487           val acc : 0.93977   \n",
      "epoch : 88    test loss : 0.16012          test acc : 0.94670   \n",
      "\n",
      "epoch : 89    train loss : 0.12482         train acc : 0.95447   \n",
      "epoch : 89    val loss : 0.19297           val acc : 0.93969   \n",
      "epoch : 89    test loss : 0.15822          test acc : 0.94811   \n",
      "\n",
      "epoch : 90    train loss : 0.12377         train acc : 0.95516   \n",
      "epoch : 90    val loss : 0.19388           val acc : 0.94179   \n",
      "epoch : 90    test loss : 0.16142          test acc : 0.94743   \n",
      "\n",
      "epoch : 91    train loss : 0.12300         train acc : 0.95526   \n",
      "epoch : 91    val loss : 0.19090           val acc : 0.94187   \n",
      "epoch : 91    test loss : 0.15734          test acc : 0.94819   \n",
      "\n",
      "epoch : 92    train loss : 0.12509         train acc : 0.95501   \n",
      "epoch : 92    val loss : 0.19339           val acc : 0.94058   \n",
      "epoch : 92    test loss : 0.16193          test acc : 0.94819   \n",
      "\n",
      "epoch : 93    train loss : 0.12247         train acc : 0.95492   \n",
      "epoch : 93    val loss : 0.19318           val acc : 0.94295   \n",
      "epoch : 93    test loss : 0.15811          test acc : 0.94783   \n",
      "\n",
      "epoch : 94    train loss : 0.12348         train acc : 0.95385   \n",
      "epoch : 94    val loss : 0.19485           val acc : 0.93941   \n",
      "epoch : 94    test loss : 0.15959          test acc : 0.94521   \n",
      "\n",
      "epoch : 95    train loss : 0.12155         train acc : 0.95578   \n",
      "epoch : 95    val loss : 0.19152           val acc : 0.94275   \n",
      "epoch : 95    test loss : 0.15865          test acc : 0.94783   \n",
      "\n",
      "epoch : 96    train loss : 0.12204         train acc : 0.95437   \n",
      "epoch : 96    val loss : 0.19483           val acc : 0.94050   \n",
      "epoch : 96    test loss : 0.16040          test acc : 0.94670   \n",
      "\n",
      "epoch : 97    train loss : 0.12490         train acc : 0.95337   \n",
      "epoch : 97    val loss : 0.19566           val acc : 0.93913   \n",
      "epoch : 97    test loss : 0.16222          test acc : 0.94558   \n",
      "\n",
      "epoch : 98    train loss : 0.12145         train acc : 0.95611   \n",
      "epoch : 98    val loss : 0.19672           val acc : 0.94187   \n",
      "epoch : 98    test loss : 0.15980          test acc : 0.94779   \n",
      "\n",
      "epoch : 99    train loss : 0.12185         train acc : 0.95562   \n",
      "epoch : 99    val loss : 0.19094           val acc : 0.94275   \n",
      "epoch : 99    test loss : 0.16114          test acc : 0.94851   \n",
      "\n",
      "epoch : 100   train loss : 0.12174         train acc : 0.95562   \n",
      "epoch : 100   val loss : 0.19250           val acc : 0.94384   \n",
      "epoch : 100   test loss : 0.16187          test acc : 0.94594   \n",
      "\n",
      "\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\\n\")\n",
    "for epoch in range(epoches):\n",
    "    \n",
    "    train_model(model, trainLoader, criterion, optimizer, scheduler, device)\n",
    "    train_acc, train_loss = get_loss_train(model, trainLoader, criterion, device)\n",
    "    print(\"epoch : {:<5} train loss : {:<15.5f} train acc : {:<10.5f}\".format(epoch+1, train_loss, train_acc))\n",
    "    \n",
    "    val_acc, val_loss = val_model(model, valLoader, criterion, device)\n",
    "    print(\"epoch : {:<5} val loss : {:<17.5f} val acc : {:<10.5f}\".format(epoch+1, val_loss, val_acc))\n",
    "\n",
    "#     you can print the test history through this code\n",
    "#     test_acc, test_loss = val_model(model, testLoader, criterion, device)\n",
    "#     print(\"epoch : {:<5} test loss : {:<16.5f} test acc : {:<10.5f}\\n\".format(epoch+1, test_loss, test_acc))\n",
    "\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    torch.save(model.state_dict(), './model'+str(epoch+1)+'.pth')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "print(\"\\nTraining Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48d8bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (act): ReLU()\n",
       "  (hidden1): Linear(in_features=9, out_features=100, bias=True)\n",
       "  (hidden2): Linear(in_features=100, out_features=300, bias=True)\n",
       "  (hidden3): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (hiddenfinal): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'model.pth' # adjust this to your saved model\n",
    "\n",
    "model = MLP(9)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6273b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\\") # adjust this to your file directory\n",
    "finalset = TrainDataset('.csv') # adjust this to your file name\n",
    "finalLoader = torch.utils.data.DataLoader(finalset, batch_size=1, shuffle = False)\n",
    "\n",
    "print_pred(model, finalLoader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31727c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(range(epoch+1), history['train_loss'], label='Loss', color='red')\n",
    "plt.plot(range(epoch+1), history['val_loss'], label='Loss', color='blue')\n",
    "# you can plot the test loss history through this code\n",
    "# plt.plot(range(epoch+1), history['test_loss'], label='Loss', color='green')\n",
    "\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(range(epoch+1), history['train_acc'], label='Accuracy', color='red')\n",
    "plt.plot(range(epoch+1), history['val_acc'], label='Accuracy', color='blue')\n",
    "# you can plot the test accuracy history through this code\n",
    "# plt.plot(range(epoch+1), history['test_acc'], label='Accuracy', color='green')\n",
    "\n",
    "plt.title('Accuracy history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
